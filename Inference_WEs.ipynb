{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from ollama import chat\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Create a SentenceTransformer instance with the stella_en_1.5B_v5 model\n",
    "word_embedding = SentenceTransformer(\"dunzhang/stella_en_400M_v5\", device=\"mps\", config_kwargs={\"use_memory_efficient_attention\": False, \"unpad_inputs\": False}, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2Embedding():\n",
    "    def __init__(self, model):\n",
    "        \"\"\"\n",
    "        The constructor takes in a text-embedding model object (e.g., \n",
    "        a SentenceTransformer instance or any other encoding model).\n",
    "        \n",
    "        :param model: A text embedding model with a .encode() method.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "    def sentence2vector(self, sentences, name='product_description'):\n",
    "        \"\"\"\n",
    "        Encodes a given text (or list of texts) into an embedding.\n",
    "        \n",
    "        :param sentences: The text input(s) to encode.\n",
    "        :param name: Optional identifier for debugging/logging purposes.\n",
    "        :return: The raw embedding vector (or a list of vectors).\n",
    "        \"\"\"\n",
    "        print(f\"Encoding sentences for feature '{name}'...\")\n",
    "        vector = self.model.encode(sentences)\n",
    "        return vector\n",
    "\n",
    "    def transform(self, input):\n",
    "        \"\"\"\n",
    "        A convenience method that calls sentence2vector() and reshapes \n",
    "        the resulting embedding(s) to a fixed shape of (1, 1024). \n",
    "        This implies the model outputs a 1024-dimensional embedding.\n",
    "        \n",
    "        :param input: The text input to encode.\n",
    "        :return: A (1, 1024) NumPy array representing the single text embedding.\n",
    "        \"\"\"\n",
    "        embedding = self.sentence2vector(input)\n",
    "        return embedding.reshape(1, 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from 'model_gbm.txt' file\n",
    "\n",
    "gbm = lightgbm.Booster(model_file='lightgbm_model_light_we.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sentences for feature 'product_description'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharva/anaconda3/envs/SaleSense/lib/python3.10/site-packages/transformers/modeling_utils.py:1141: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 1: Old Score=0.3502, New Score=0.3542\n",
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 2: Old Score=0.3542, New Score=0.4417\n",
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 3: Old Score=0.4417, New Score=0.3888\n",
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 4: Old Score=0.4417, New Score=0.4380\n",
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 5: Old Score=0.4417, New Score=0.4053\n",
      "Encoding sentences for feature 'product_description'...\n",
      "Iteration 6: Old Score=0.4417, New Score=0.3382\n",
      "\n",
      "Old description: Authentic vintage Chanel made out of luxurious black lambskin. Featuring gold CC closure. Size W: 25cm H: 17cm Size D: 2cm. Shoulder height: 94cm. Inside lining has been fully replaced. Comes with ribbon.\n",
      "\n",
      "Best description:  This vintage Chanel masterpiece showcases impeccable craftsmanship, with luxurious black lambskin and a bold gold CC closure that epitomizes sophistication. Measuring 25cm x 17cm x 2cm, the compact size belies its elegant proportions, perfectly suited for making a stylish statement. A generous shoulder drop of 94cm amplifies its refined charm. Featuring a replaced interior lining, this piece remains intact and is elevated by a charming ribbon accessory, solidifying its status as a highly sought-after collector's item.\n",
      "\n",
      "Best score: 0.4417386310387718\n",
      "\n",
      "Percent of improvment: 26.151%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the initial description text\n",
    "example = \"Authentic vintage Chanel made out of luxurious black lambskin. Featuring gold CC closure. Size W: 25cm H: 17cm Size D: 2cm. Shoulder height: 94cm. Inside lining has been fully replaced. Comes with ribbon.\"\n",
    "# example = 'int pedro = 9'\n",
    "# Transform the text into an embedding \n",
    "transform_embedding = Text2Embedding(word_embedding)\n",
    "example_embedding = transform_embedding.transform(example)\n",
    "\n",
    "# Define a threshold for the score and the maximum number of iterations\n",
    "score_threshold = 0.9\n",
    "max_iterations = 6\n",
    "\n",
    "# Use a GBM model to predict the \"score\" for the current description\n",
    "best_score = gbm.predict(example_embedding)\n",
    "best_score = float(best_score[0])\n",
    "\n",
    "# Keep track of the first (original) description and its score\n",
    "first_example = example\n",
    "first_score = best_score\n",
    "\n",
    "# Start iterating until we meet our threshold or reach the max_iterations\n",
    "i = 1\n",
    "while best_score < score_threshold and i <= max_iterations:\n",
    "    # Prepare the prompt as messages for the chat model\n",
    "    #  - The system message instructs the model to improve the description\n",
    "    #  - The user message includes the current score and the text to improve\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You task is to improve the description based on the 'score' , \"\n",
    "                \"try to maximize 'score' which indicates how good is the description, \"\n",
    "                \"also keep all the essential information like (sizes, colors, brand, etc). \"\n",
    "                \"Note just return the 'Description'\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Score: {best_score:.2f} | Description: {example}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call the chat model to get a new/improved description\n",
    "    response = chat(model=\"llama3.2\", messages=messages)\n",
    "    \n",
    "    # Extract the new description from the response\n",
    "    # Assumes the response content is in the format: \"Description: ...\"\n",
    "    example = response['message']['content'].split(':')[-1]\n",
    "\n",
    "    # Transform the new description to get its embedding\n",
    "    example_embedding = transform_embedding.transform(example)\n",
    "    \n",
    "    # Predict the score of this new description\n",
    "    new_score = gbm.predict(example_embedding)\n",
    "    new_score = float(new_score[0])\n",
    "\n",
    "    # Print debug information: how the score changed from old to new\n",
    "    print(f\"Iteration {i}: Old Score={best_score:.4f}, New Score={new_score:.4f}\")\n",
    "\n",
    "    # If the new score is better, update our best_score and best_text\n",
    "    if new_score > best_score:\n",
    "        best_score = new_score\n",
    "        best_text = example\n",
    "\n",
    "    i += 1  # Move to the next iteration\n",
    "\n",
    "# Once we exit the loop, track the final score\n",
    "last_score = best_score\n",
    "\n",
    "# Calculate the percentage improvement over the first/original score\n",
    "percent_of_change = (((last_score - first_score) / first_score) * 100)\n",
    "\n",
    "# Print out the old and best descriptions with their corresponding scores\n",
    "print(f'\\nOld description: {first_example}')\n",
    "print(f\"\\nBest description: {best_text}\")\n",
    "print(f\"\\nBest score: {best_score}\")\n",
    "print(f\"\\nPercent of improvment: {percent_of_change:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4417386310387718"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISC_C_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
